import re
import json
import os
from tqdm import tqdm
from gensim.models import Word2Vec
import gc

class Word2VecCBOW:
    
    def __init__(self, config, logger):
        self.config = config
        self.logger = logger
        self.word2vec_params = self._to_dict(self.config.model.word2vec_params)
        self.custom_params = self._to_dict(self.config.model.custom_params)
        self.save_path = os.path.join(
            self.config.path.WORD2VEC_OUT_PATH,
            self.config.model.custom_params.save_path
        )
        self.model = None
        
        self.logger.info("Initializing Word2VecCBOW")
        self.logger.info(f"Save path: {self.save_path}")
        
        # Ensure the directory for save_path exists
        self.ensure_directory(self.save_path)
        
    def _to_dict(self, obj):
        if isinstance(obj, dict):
            return {k: self._to_dict(v) for k, v in obj.items()}
        elif hasattr(obj, "__dict__"):
            return self._to_dict(obj.__dict__)
        elif isinstance(obj, (list, tuple)):
            return [self._to_dict(item) for item in obj]
        else:
            return obj
        
    def ensure_directory(self, path):
        directory = os.path.dirname(path)
        if directory and not os.path.exists(directory):
            os.makedirs(directory)
            self.logger.info(f"Created directory: {directory}")
        
    def save_checkpoint(self, epoch):
        checkpoint_path = f"{self.save_path}_checkpoint_epoch_{epoch}.model"
        self.model.save(checkpoint_path)
        self.logger.info(f"Checkpoint saved to {checkpoint_path}")

    def load_checkpoint(self, epoch):
        checkpoint_path = f"{self.save_path}_checkpoint_epoch_{epoch}.model"
        self.model = Word2Vec.load(checkpoint_path)
        self.logger.info(f"Checkpoint loaded from {checkpoint_path}")

    def build_vocab(self, file_paths):
        self.logger.info("Building vocabulary...")
        sentences = self.load_sentences(file_paths)
        self.model.build_vocab(sentences, progress_per=10000)
        self.logger.info("Vocabulary built.")

    def train(self, file_paths, start_epoch=0):
        if start_epoch == 0:
            self.logger.info("Initializing new Word2Vec model")
            self.logger.debug(f"Word2Vec parameters: {self.word2vec_params}")
            self.model = Word2Vec(**self.word2vec_params)
            self.build_vocab(file_paths)
        else:
            self.logger.info(f"Resuming training from epoch {start_epoch}")
            self.load_checkpoint(start_epoch - 1)
        
        for epoch in range(start_epoch, self.custom_params['epochs']):
            self.logger.info(f"Starting epoch {epoch + 1}/{self.custom_params['epochs']}")
            sentences = self.load_sentences(file_paths)
            self.model.train(sentences, total_examples=self.model.corpus_count, epochs=1)
            self.save_checkpoint(epoch)
            self.logger.info(f"Epoch {epoch + 1}/{self.custom_params['epochs']} completed")
            gc.collect()

    def load_sentences(self, file_paths):
        for file_path in tqdm(file_paths, desc="Loading files"):
            yield from self.parse_fcg_json_file(file_path)

    def parse_fcg_json_file(self, file_path):
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            instructions = [instr for func in data.values() for instr in func.get('instructions', [])]
            self.logger.debug(f"Parsed {len(instructions)} instructions from {file_path}.")
            return [re.findall(r'\w+', instruction) for instruction in instructions]
        except Exception as e:
            self.logger.error(f"Error processing file {file_path}: {e}")
            return []

    def run(self, resume_from_epoch=0):
        self.logger.info("Starting Word2Vec training process")
        
        # Get training data file paths
        training_directory = self.config.path.NORMALIZED_OUT_PATH
        training_file_paths = [os.path.join(root, file) for root, _, files in os.walk(training_directory) for file in files if file.endswith('.json')]
        self.logger.info(f"Found {len(training_file_paths)} training JSON files for processing")

        # Get prediction data file paths (if available)
        prediction_directory = self.config.folder.PREDICT_NORMALIZED_DIR
        prediction_file_paths = []
        if os.path.exists(prediction_directory):
            prediction_file_paths = [os.path.join(root, file) for root, _, files in os.walk(prediction_directory) for file in files if file.endswith('.json')]
            self.logger.info(f"Found {len(prediction_file_paths)} prediction JSON files for processing")

        # Combine training and prediction file paths
        all_file_paths = training_file_paths + prediction_file_paths
        self.logger.info(f"Total files for processing: {len(all_file_paths)}")

        # Train the model
        self.train(all_file_paths, start_epoch=resume_from_epoch)
        self.logger.info("Word2Vec training process completed")
