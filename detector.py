import os
import numpy as np
import torch
import json
from typing import Any
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split
from utils.normalize_assembly import NormalizeAssembly
from utils.word2vec_cbow import Word2VecCBOW
from models.gcn_attention import GCNWithAttention
from config import Config, read_config

class MalwareDetectorImplementation:
    def __init__(self, config_path=None):
        self.config = read_config(config_path) if config_path else Config()
        self.normalizer = NormalizeAssembly(self.config.path.DEFAULT_INPUT_PATH, self.config.path.DEFAULT_OUT_PATH)
        self.word2vec_model = None
        self.gcn_model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    def mkdir(self):
        for folder in self.config.folder.__dict__.values():
            os.makedirs(folder, exist_ok=True)

    def extractFeature(self) -> list:
        self.normalizer.process_json_files()
        
        features = []
        labels = []
        
        for category in ['benign', 'malware']:
            category_path = os.path.join(self.config.path.DEFAULT_OUT_PATH, category)
            label = 0 if category == 'benign' else 1
            
            for root, _, files in os.walk(category_path):
                for file in files:
                    if file.endswith('.json'):
                        file_path = os.path.join(root, file)
                        with open(file_path, 'r') as f:
                            data = json.load(f)
                        
                        file_features = self.process_json_data(data)
                        features.append(file_features)
                        labels.append(label)
        
        self.labels = np.array(labels)
        return features

    def process_json_data(self, data):
        instructions = []
        for key, value in data.items():
            if isinstance(value, dict) and 'instructions' in value:
                instructions.extend(value['instructions'])
        return instructions

    def vectorize(self) -> np.array:
        features = self.extractFeature()
        
        word2vec_params = self.config.model.word2vec_params.dict()
        custom_params = self.config.model.custom_params.dict()
        self.word2vec_model = Word2VecCBOW(word2vec_params, custom_params)
        
        all_instructions = [inst for file_features in features for inst in file_features]
        self.word2vec_model.train(all_instructions)
        
        vectorized_features = []
        for file_features in features:
            file_vector = []
            for instruction in file_features:
                instruction_vector = self.word2vec_model.vectorize_instruction(instruction)
                file_vector.append(instruction_vector)
            vectorized_features.append(np.mean(file_vector, axis=0))
        
        return np.array(vectorized_features)

    def model(self, training: bool = True) -> Any:
        vectorized_data = self.vectorize()
        
        dataset = []
        for i, features in enumerate(vectorized_data):
            x = torch.tensor(features, dtype=torch.float).unsqueeze(0)
            edge_index = torch.tensor([[0], [0]], dtype=torch.long)
            data = Data(x=x, edge_index=edge_index, y=torch.tensor([self.labels[i]], dtype=torch.long))
            dataset.append(data)
        
        train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)
        self.train_loader = DataLoader(train_dataset, batch_size=self.config.model.gcn_params.batch_size, shuffle=True)
        self.test_loader = DataLoader(test_dataset, batch_size=self.config.model.gcn_params.batch_size, shuffle=False)
        
        gcn_params = self.config.model.gcn_params
        self.gcn_model = GCNWithAttention(
            num_features=gcn_params.num_features,
            hidden_channels=gcn_params.hidden_channels,
            num_classes=gcn_params.num_classes,
            num_layers=gcn_params.num_layers,
            dropout_rate=gcn_params.dropout_rate
        ).to(self.device)
        
        if training:
            self.train_gcn_model()
        else:
            self.load_gcn_model()
        
        return self.gcn_model
    
    def predict(self) -> np.array:
        if self.gcn_model is None:
            raise ValueError("Model has not been trained or loaded. Call model() first.")
        
        predictions = []
        self.gcn_model.eval()
        with torch.no_grad():
            for data in self.test_loader:
                data = data.to(self.device)
                out = self.gcn_model(data.x, data.edge_index, data.batch)
                pred = out.argmax(dim=1)
                predictions.extend(pred.cpu().numpy())
        
        return np.array(predictions)

    def train_gcn_model(self):
        gcn_params = self.config.model.gcn_params
        optimizer = torch.optim.Adam(self.gcn_model.parameters(), lr=gcn_params.learning_rate)
        criterion = torch.nn.NLLLoss()

        for epoch in range(gcn_params.epochs):
            self.gcn_model.train()
            total_loss = 0
            for data in self.train_loader:
                data = data.to(self.device)
                optimizer.zero_grad()
                out = self.gcn_model(data.x, data.edge_index, data.batch)
                loss = criterion(out, data.y)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
            
            print(f"Epoch {epoch+1}/{gcn_params.epochs}, Loss: {total_loss/len(self.train_loader):.4f}")
        
        # Save the trained model
        torch.save(self.gcn_model.state_dict(), gcn_params.save_path)
        print(f"Model saved to {gcn_params.save_path}")

    def load_gcn_model(self):
        gcn_params = self.config.model.gcn_params
        if os.path.exists(gcn_params.save_path):
            self.gcn_model.load_state_dict(torch.load(gcn_params.save_path))
            print(f"Model loaded from {gcn_params.save_path}")
        else:
            raise FileNotFoundError(f"No pre-trained model found at {gcn_params.save_path}")

if __name__ == "__main__":
    detector = MalwareDetectorImplementation()
    detector.mkdir()
    
    print("Extracting features...")
    features = detector.extractFeature()
    print(f"Extracted features for {len(features)} files.")
    
    print("\nVectorizing features...")
    vectorized_features = detector.vectorize()
    print(f"Vectorized features shape: {vectorized_features.shape}")
    
    print("\nTraining model...")
    model = detector.model(training=True)
    print("Model training complete.")
    
    print("\nMaking predictions...")
    predictions = detector.predict()
    print(f"Predictions shape: {predictions.shape}")
    print(f"Unique prediction classes: {np.unique(predictions)}")